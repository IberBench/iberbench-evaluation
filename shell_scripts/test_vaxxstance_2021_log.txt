/data/research/sharedData/conda_envs/iborrego-lmeval-newnewtask/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `PYTORCH_PRETRAINED_BERT_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/research/sharedData/conda_envs/iborrego-lmeval-newnewtask/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `PYTORCH_TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/research/sharedData/conda_envs/iborrego-lmeval-newnewtask/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2025-02-04:14:41:39,319 INFO     [__main__.py:284] Verbosity set to INFO
2025-02-04:14:41:39,421 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-04:14:42:13,429 WARNING  [__main__.py:317]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-02-04:14:42:13,431 INFO     [__main__.py:369] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`
2025-02-04:14:42:13,436 INFO     [__main__.py:381] Selected Tasks: ['vaxxstance_2021']
2025-02-04:14:42:13,449 INFO     [evaluator.py:165] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-02-04:14:42:13,449 INFO     [evaluator.py:202] Initializing hf model, with arguments: {'pretrained': 'EleutherAI/pythia-2.8b', 'trust_remote_code': True, 'parallelize': True, 'max_length': 2048}
2025-02-04:14:42:18,604 INFO     [huggingface.py:358] Model parallel was set to True, setting max memory per GPU to {0: 50759598080, 1: 50759598080} and device map to auto
The `GPTNeoXSdpaAttention` class is deprecated in favor of simply modifying the `config._attn_implementation`attribute of the `GPTNeoXAttention` class! It will be removed in v4.48
2025-02-04:14:42:22,503 WARNING  [task.py:816] [Task: vaxxstance_basque] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2025-02-04:14:42:22,504 WARNING  [task.py:816] [Task: vaxxstance_basque] metric f1 is defined, but higher_is_better is not. using default higher_is_better=True
Using the latest cached version of the dataset since iberbench/iberlef_vaxxstance_2021_basque couldn't be found on the Hugging Face Hub
2025-02-04:14:42:34,869 WARNING  [load.py:1444] Using the latest cached version of the dataset since iberbench/iberlef_vaxxstance_2021_basque couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /data/research/users/iborrego/cache/huggingface_cache/iberbench___iberlef_vaxxstance_2021_basque/default/0.0.0/9e182cf200ddad0b6dade13ee17503965c15ae20 (last modified on Tue Feb  4 14:40:27 2025).
2025-02-04:14:42:34,879 WARNING  [cache.py:94] Found the latest cached dataset configuration 'default' at /data/research/users/iborrego/cache/huggingface_cache/iberbench___iberlef_vaxxstance_2021_basque/default/0.0.0/9e182cf200ddad0b6dade13ee17503965c15ae20 (last modified on Tue Feb  4 14:40:27 2025).
2025-02-04:14:42:35,059 WARNING  [task.py:816] [Task: vaxxstance_spanish] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2025-02-04:14:42:35,059 WARNING  [task.py:816] [Task: vaxxstance_spanish] metric f1 is defined, but higher_is_better is not. using default higher_is_better=True
2025-02-04:14:42:37,911 INFO     [task.py:420] Building contexts for vaxxstance_spanish on rank 0...
  0%|          | 0/694 [00:00<?, ?it/s] 23%|██▎       | 159/694 [00:00<00:00, 1584.50it/s] 46%|████▌     | 318/694 [00:00<00:00, 1315.13it/s] 65%|██████▌   | 453/694 [00:00<00:00, 1066.27it/s] 81%|████████▏ | 565/694 [00:00<00:00, 1061.68it/s] 99%|█████████▉| 687/694 [00:00<00:00, 1109.43it/s]100%|██████████| 694/694 [00:00<00:00, 1142.39it/s]
2025-02-04:14:42:38,550 INFO     [task.py:420] Building contexts for vaxxstance_basque on rank 0...
  0%|          | 0/312 [00:00<?, ?it/s] 52%|█████▏    | 162/312 [00:00<00:00, 1615.27it/s]100%|██████████| 312/312 [00:00<00:00, 1618.65it/s]
2025-02-04:14:42:38,755 INFO     [evaluator.py:513] Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/3018 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/3018 [00:09<7:56:12,  9.47s/it]Running loglikelihood requests:   6%|▋         | 193/3018 [00:10<01:46, 26.43it/s]Running loglikelihood requests:  13%|█▎        | 385/3018 [00:10<00:46, 57.01it/s]Running loglikelihood requests:  19%|█▉        | 577/3018 [00:11<00:26, 91.54it/s]Running loglikelihood requests:  25%|██▌       | 769/3018 [00:11<00:17, 130.10it/s]Running loglikelihood requests:  32%|███▏      | 961/3018 [00:12<00:11, 171.73it/s]Running loglikelihood requests:  38%|███▊      | 1153/3018 [00:12<00:08, 216.09it/s]Running loglikelihood requests:  45%|████▍     | 1345/3018 [00:13<00:06, 263.63it/s]Running loglikelihood requests:  51%|█████     | 1537/3018 [00:13<00:04, 310.80it/s]Running loglikelihood requests:  57%|█████▋    | 1729/3018 [00:13<00:03, 356.57it/s]Running loglikelihood requests:  64%|██████▎   | 1921/3018 [00:14<00:02, 396.12it/s]Running loglikelihood requests:  70%|███████   | 2113/3018 [00:14<00:02, 437.42it/s]Running loglikelihood requests:  76%|███████▋  | 2305/3018 [00:14<00:01, 473.02it/s]Running loglikelihood requests:  83%|████████▎ | 2497/3018 [00:15<00:01, 514.36it/s]Running loglikelihood requests:  89%|████████▉ | 2689/3018 [00:15<00:00, 565.61it/s]Running loglikelihood requests:  91%|█████████ | 2751/3018 [00:15<00:00, 545.83it/s]Running loglikelihood requests:  95%|█████████▌| 2881/3018 [00:15<00:00, 551.52it/s]Running loglikelihood requests: 100%|██████████| 3018/3018 [00:15<00:00, 189.38it/s]
2025-02-04:14:43:02,870 INFO     [evaluation_tracker.py:269] Output path not provided, skipping saving results aggregated
Passed argument batch_size = auto:16.0. Detecting largest batch size
Determined largest batch size: 64
Passed argument batch_size = auto:16.0. Detecting largest batch size
Determined largest batch size: 64
hf (pretrained=EleutherAI/pythia-2.8b,trust_remote_code=True,parallelize=True,max_length=2048,trust_remote_code=True), gen_kwargs: (None), limit: 1000.0, num_fewshot: None, batch_size: auto:16 (64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64)
|      Tasks       |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|------------------|------:|------|-----:|------|---|-----:|---|------|
|vaxxstance_basque |      1|none  |     0|acc   |↑  |0.4327|±  |0.0281|
|                  |       |none  |     0|f1    |↑  |0.2013|±  |   N/A|
|vaxxstance_spanish|      1|none  |     0|acc   |↑  |0.2795|±  |0.0170|
|                  |       |none  |     0|f1    |↑  |0.1456|±  |   N/A|

